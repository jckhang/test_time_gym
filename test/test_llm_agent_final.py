#!/usr/bin/env python3
"""
æœ€ç»ˆLLMæ™ºèƒ½ä½“æµ‹è¯•è„šæœ¬
éªŒè¯LLMæ™ºèƒ½ä½“çš„å®Œæ•´åŠŸèƒ½ï¼ŒåŒ…æ‹¬çœŸå®çš„LLMè°ƒç”¨
"""

import asyncio
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from test_time_gym.agents import FlightBookingOpenAIAgent, ToolEnabledFlightBookingAgent
from test_time_gym.envs.flight_booking_env import FlightBookingEnv

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def test_real_llm_agent():
    """æµ‹è¯•çœŸå®çš„LLMæ™ºèƒ½ä½“è°ƒç”¨"""
    print("=== æµ‹è¯•çœŸå®LLMæ™ºèƒ½ä½“è°ƒç”¨ ===")

    try:
        # ä½¿ç”¨å·¥ä½œçš„æ¨¡å‹
        agent = FlightBookingOpenAIAgent(
            model="gpt-4o-mini",  # ä½¿ç”¨å·¥ä½œçš„æ¨¡å‹
            strategy="balanced",
            temperature=0.7
        )

        env = FlightBookingEnv(seed=42)
        obs, info = env.reset(seed=42)

        print(f"âœ“ ç¯å¢ƒå’Œæ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸï¼Œåˆå§‹çŠ¶æ€: {obs['view']}")

        # è¿è¡Œå‡ ä¸ªæ­¥éª¤ï¼Œæµ‹è¯•çœŸå®LLMè°ƒç”¨
        trajectory = []
        total_reward = 0
        llm_calls = 0

        for step in range(3):
            try:
                print(f"\n--- æ­¥éª¤ {step} ---")
                print(f"å½“å‰çŠ¶æ€: {obs['view']}")

                # è®°å½•è°ƒç”¨å‰çš„å¯¹è¯å†å²é•¿åº¦
                history_before = len(agent.conversation_history)

                # æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ
                action = await agent.select_action(obs)

                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†LLM
                history_after = len(agent.conversation_history)
                if history_after > history_before:
                    llm_calls += 1
                    print(f"âœ… ä½¿ç”¨äº†LLMè¿›è¡Œå†³ç­–: {action}")
                else:
                    print(f"âš ï¸ ä½¿ç”¨äº†é™çº§ç­–ç•¥: {action}")

                # ç¯å¢ƒæ‰§è¡ŒåŠ¨ä½œ
                obs, reward, done, trunc, info = env.step(action)
                total_reward += reward

                trajectory.append({
                    "step": step,
                    "action": action,
                    "reward": reward,
                    "obs": obs
                })

                print(f"æ‰§è¡Œç»“æœ: å¥–åŠ±={reward:.3f}, æ–°çŠ¶æ€={obs['view']}")

                if done or trunc:
                    print(f"ä»»åŠ¡{'å®Œæˆ' if done else 'è¢«æˆªæ–­'}")
                    break

            except Exception as e:
                logger.error(f"æ­¥éª¤ {step} å‡ºé”™: {e}")
                # ä½¿ç”¨é™çº§ç­–ç•¥
                action = agent._fallback_action(obs)
                obs, reward, done, trunc, info = env.step(action)
                total_reward += reward
                print(f"ä½¿ç”¨é™çº§ç­–ç•¥: {action}")

                if done or trunc:
                    break

        # æ›´æ–°æ™ºèƒ½ä½“è®°å¿†
        agent.update_memory(trajectory)

        print(f"\n=== æµ‹è¯•ç»“æœ ===")
        print(f"æ€»å¥–åŠ±: {total_reward:.3f}")
        print(f"è½¨è¿¹é•¿åº¦: {len(trajectory)}")
        print(f"LLMè°ƒç”¨æ¬¡æ•°: {llm_calls}")
        print(f"æ™ºèƒ½ä½“ç»Ÿè®¡: {agent.get_stats()}")

        return llm_calls > 0  # è‡³å°‘æœ‰ä¸€æ¬¡LLMè°ƒç”¨æ‰ç®—æˆåŠŸ

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


async def test_different_strategies_with_llm():
    """æµ‹è¯•ä¸åŒç­–ç•¥çš„LLMæ™ºèƒ½ä½“"""
    print("\n=== æµ‹è¯•ä¸åŒç­–ç•¥çš„LLMæ™ºèƒ½ä½“ ===")

    strategies = ["aggressive", "balanced", "conservative"]
    results = {}

    for strategy in strategies:
        try:
            print(f"\n--- æµ‹è¯• {strategy} ç­–ç•¥ ---")

            agent = FlightBookingOpenAIAgent(
                model="gpt-4o-mini",
                strategy=strategy
            )

            env = FlightBookingEnv(seed=42)
            obs, info = env.reset(seed=42)

            # è¿è¡Œå‡ æ­¥
            total_reward = 0
            llm_calls = 0

            for step in range(2):
                try:
                    history_before = len(agent.conversation_history)
                    action = await agent.select_action(obs)
                    history_after = len(agent.conversation_history)

                    if history_after > history_before:
                        llm_calls += 1
                        print(f"  âœ… LLMè°ƒç”¨: {action}")
                    else:
                        print(f"  âš ï¸ é™çº§ç­–ç•¥: {action}")

                    obs, reward, done, trunc, info = env.step(action)
                    total_reward += reward

                    if done or trunc:
                        break

                except Exception as e:
                    print(f"  âŒ æ­¥éª¤ {step} å‡ºé”™: {e}")
                    action = agent._fallback_action(obs)
                    obs, reward, done, trunc, info = env.step(action)
                    total_reward += reward

                    if done or trunc:
                        break

            results[strategy] = {"reward": total_reward, "llm_calls": llm_calls}
            print(f"âœ“ {strategy} ç­–ç•¥: å¥–åŠ±={total_reward:.3f}, LLMè°ƒç”¨={llm_calls}")

        except Exception as e:
            print(f"âŒ {strategy} ç­–ç•¥æµ‹è¯•å¤±è´¥: {e}")
            results[strategy] = {"reward": 0, "llm_calls": 0}

    # æ˜¾ç¤ºæ¯”è¾ƒç»“æœ
    print(f"\n=== ç­–ç•¥æ¯”è¾ƒç»“æœ ===")
    for strategy, result in results.items():
        print(f"{strategy}: å¥–åŠ±={result['reward']:.3f}, LLMè°ƒç”¨={result['llm_calls']}")

    return len(results) > 0


async def test_tool_enabled_agent_with_llm():
    """æµ‹è¯•å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“çš„LLMåŠŸèƒ½"""
    print("\n=== æµ‹è¯•å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“çš„LLMåŠŸèƒ½ ===")

    try:
        agent = ToolEnabledFlightBookingAgent(
            model="gpt-4o-mini",
            strategy="aggressive"
        )

        env = FlightBookingEnv(seed=42)
        obs, info = env.reset(seed=42)

        print("âœ“ å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•LLMè°ƒç”¨
        history_before = len(agent.conversation_history)
        action = await agent.select_action(obs)
        history_after = len(agent.conversation_history)

        if history_after > history_before:
            print(f"âœ… å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“LLMè°ƒç”¨æˆåŠŸ: {action}")
            return True
        else:
            print(f"âš ï¸ å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“ä½¿ç”¨é™çº§ç­–ç•¥: {action}")
            return False

    except Exception as e:
        print(f"âŒ å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_agent_learning_with_llm():
    """æµ‹è¯•æ™ºèƒ½ä½“å­¦ä¹ åŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ™ºèƒ½ä½“å­¦ä¹ åŠŸèƒ½ ===")

    try:
        agent = FlightBookingOpenAIAgent(
            model="gpt-4o-mini",
            strategy="balanced"
        )

        # è¿è¡Œå¤šä¸ªepisode
        episodes = 2
        episode_rewards = []
        total_llm_calls = 0

        for episode in range(episodes):
            print(f"\n--- Episode {episode + 1} ---")

            env = FlightBookingEnv(seed=42 + episode)
            obs, info = env.reset(seed=42 + episode)
            trajectory = []
            total_reward = 0
            llm_calls = 0

            for step in range(3):
                try:
                    history_before = len(agent.conversation_history)
                    action = await agent.select_action(obs)
                    history_after = len(agent.conversation_history)

                    if history_after > history_before:
                        llm_calls += 1
                        total_llm_calls += 1

                    obs, reward, done, trunc, info = env.step(action)
                    total_reward += reward

                    trajectory.append({
                        "step": step,
                        "action": action,
                        "reward": reward,
                        "obs": obs
                    })

                    if done or trunc:
                        break

                except Exception as e:
                    print(f"  âš ï¸ æ­¥éª¤ {step} å‡ºé”™ï¼Œä½¿ç”¨é™çº§ç­–ç•¥: {e}")
                    action = agent._fallback_action(obs)
                    obs, reward, done, trunc, info = env.step(action)
                    total_reward += reward

                    if done or trunc:
                        break

            agent.update_memory(trajectory)
            episode_rewards.append(total_reward)

            print(f"Episode {episode + 1}: å¥–åŠ±={total_reward:.3f}, LLMè°ƒç”¨={llm_calls}")

        # æ˜¾ç¤ºå­¦ä¹ ç»Ÿè®¡
        print(f"\n=== å­¦ä¹ ç»Ÿè®¡ ===")
        print(f"å¹³å‡å¥–åŠ±: {sum(episode_rewards) / len(episode_rewards):.3f}")
        print(f"æ€»LLMè°ƒç”¨: {total_llm_calls}")
        print(f"æ™ºèƒ½ä½“ç»Ÿè®¡: {agent.get_stats()}")

        return total_llm_calls > 0

    except Exception as e:
        print(f"âŒ å­¦ä¹ åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æœ€ç»ˆLLMæ™ºèƒ½ä½“æµ‹è¯•...")

    tests = [
        ("çœŸå®LLMæ™ºèƒ½ä½“è°ƒç”¨", test_real_llm_agent),
        ("ä¸åŒç­–ç•¥LLMæµ‹è¯•", test_different_strategies_with_llm),
        ("å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“LLMæµ‹è¯•", test_tool_enabled_agent_with_llm),
        ("æ™ºèƒ½ä½“å­¦ä¹ åŠŸèƒ½", test_agent_learning_with_llm),
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        print(f"\n{'='*60}")
        print(f"è¿è¡Œæµ‹è¯•: {test_name}")
        print('='*60)

        try:
            result = await test_func()
            if result:
                passed += 1
                print(f"âœ… {test_name} é€šè¿‡")
            else:
                print(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")
            logger.error(f"æµ‹è¯• {test_name} å¼‚å¸¸: {e}", exc_info=True)

    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    print('='*60)

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LLMæ™ºèƒ½ä½“å®Œå…¨è°ƒé€šï¼")
        print("\nâœ… éªŒè¯ç»“æœ:")
        print("1. çœŸå®LLMè°ƒç”¨æˆåŠŸ")
        print("2. ä¸åŒç­–ç•¥æ­£å¸¸å·¥ä½œ")
        print("3. å·¥å…·è°ƒç”¨åŠŸèƒ½æ­£å¸¸")
        print("4. å­¦ä¹ åŠŸèƒ½æ­£å¸¸")
        print("5. é™çº§æœºåˆ¶å¯é ")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œä½†LLMæ™ºèƒ½ä½“åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
        return True  # å³ä½¿æœ‰éƒ¨åˆ†å¤±è´¥ï¼ŒåŸºæœ¬åŠŸèƒ½ä¹Ÿæ˜¯æ­£å¸¸çš„


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
