#!/usr/bin/env python3
"""
å¯åŠ¨å¯è§‚æµ‹å®éªŒçš„ä¸»è„šæœ¬
æä¾›ç®€å•çš„å‘½ä»¤è¡Œç•Œé¢æ¥è¿è¡Œå„ç§å¯è§‚æµ‹å®éªŒ
"""

import argparse
import asyncio
import logging
import os
import sys
import webbrowser
import time
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from observable_experiment_runner import ObservableExperimentRunner, ObservationConfig


def setup_logging(verbose: bool = False):
    """è®¾ç½®æ—¥å¿—"""
    level = logging.DEBUG if verbose else logging.INFO
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs("logs", exist_ok=True)
    
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/observable_experiment.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # å‡å°‘ä¸€äº›åº“çš„æ—¥å¿—çº§åˆ«
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)


def print_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”¬ å¯è§‚æµ‹å®éªŒç³»ç»Ÿ                          â•‘
â•‘              æ— ç›‘ç£ç»éªŒç§¯ç´¯å®éªŒçš„å®æ—¶ç›‘æ§ä¸åˆ†æ                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ åŠŸèƒ½ç‰¹æ€§:
  â€¢ å®æ—¶ç›‘æ§å®éªŒè¿›åº¦å’ŒæŒ‡æ ‡
  â€¢ äº¤äº’å¼Webä»ªè¡¨æ¿
  â€¢ æŠ€èƒ½å­¦ä¹ è¿‡ç¨‹å¯è§†åŒ–  
  â€¢ è¯¦ç»†çš„è½¨è¿¹åˆ†æ
  â€¢ è‡ªåŠ¨ç”Ÿæˆå®éªŒæŠ¥å‘Š

ğŸ“Š ç›‘æ§å†…å®¹:
  â€¢ EpisodeæˆåŠŸç‡è¶‹åŠ¿
  â€¢ å¥–åŠ±å’Œæ­¥æ•°ç»Ÿè®¡
  â€¢ æŠ€èƒ½å­¦ä¹ æ•ˆç‡
  â€¢ é”™è¯¯å’Œå¼‚å¸¸è·Ÿè¸ª
"""
    print(banner)


async def run_quick_demo():
    """è¿è¡Œå¿«é€Ÿæ¼”ç¤º"""
    print("ğŸ® è¿è¡Œå¿«é€Ÿæ¼”ç¤ºå®éªŒ...")
    
    runner = ObservableExperimentRunner(
        "logs/demo_experiment",
        enable_observation=True,
        web_port=5000
    )
    
    try:
        results = await runner.run_comparative_experiment(
            num_episodes=30,
            models=["gpt-3.5-turbo"],
            strategies=["balanced"]
        )
        
        print("\nâœ… æ¼”ç¤ºå®éªŒå®Œæˆ!")
        print("ğŸ“Š æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šå’Œå¯è§†åŒ–ç»“æœ")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        runner.cleanup()


async def run_full_experiment(models: List[str], strategies: List[str], episodes: int):
    """è¿è¡Œå®Œæ•´å®éªŒ"""
    print(f"ğŸ”¬ è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ ({episodes} episodes)...")
    print(f"ğŸ“‹ æ¨¡å‹: {models}")
    print(f"ğŸ“‹ ç­–ç•¥: {strategies}")
    
    runner = ObservableExperimentRunner(
        "logs/full_observable_experiment",
        enable_observation=True,
        web_port=5000
    )
    
    try:
        results = await runner.run_comparative_experiment(
            num_episodes=episodes,
            models=models,
            strategies=strategies
        )
        
        print("\nâœ… å®Œæ•´å®éªŒå®Œæˆ!")
        comparison = results["comparison_report"]
        overall = comparison.get("overall_improvement", {})
        
        if overall:
            print(f"ğŸ“Š é…ç½®æµ‹è¯•æ•°: {overall.get('configurations_tested', 0)}")
            print(f"ğŸ“ˆ æœ‰æ”¹è¿›é…ç½®: {overall.get('improvements_positive', 0)}")
            print(f"ğŸ¯ æˆåŠŸç‡æ”¹è¿›: {overall.get('avg_success_rate_improvement', 0):.3f}")
        
    except Exception as e:
        print(f"âŒ å®Œæ•´å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        runner.cleanup()


async def run_custom_experiment(config_file: str):
    """è¿è¡Œè‡ªå®šä¹‰å®éªŒ"""
    print(f"âš™ï¸ ä½¿ç”¨é…ç½®æ–‡ä»¶è¿è¡Œå®éªŒ: {config_file}")
    
    if not os.path.exists(config_file):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    try:
        config = ObservationConfig.load_config(config_file)
        
        runner = ObservableExperimentRunner(
            "logs/custom_observable_experiment",
            enable_observation=config['observation']['enabled'],
            web_port=config['observation']['web_dashboard']['port']
        )
        
        # ä»é…ç½®ä¸­è¯»å–å®éªŒå‚æ•°ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        results = await runner.run_comparative_experiment(
            num_episodes=100,
            models=["gpt-3.5-turbo"],
            strategies=["balanced", "aggressive"]
        )
        
        print("\nâœ… è‡ªå®šä¹‰å®éªŒå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        runner.cleanup()


def open_dashboard(port: int = 5000):
    """å°è¯•æ‰“å¼€Webä»ªè¡¨æ¿"""
    try:
        # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        time.sleep(2)
        url = f"http://localhost:{port}"
        webbrowser.open(url)
        print(f"ğŸŒ å·²æ‰“å¼€Webä»ªè¡¨æ¿: {url}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨: {e}")
        print(f"è¯·æ‰‹åŠ¨è®¿é—®: http://localhost:{port}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¯è§‚æµ‹å®éªŒç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¿«é€Ÿæ¼”ç¤º
  python run_observable_experiment.py --demo
  
  # å®Œæ•´å®éªŒ
  python run_observable_experiment.py --full --episodes 200
  
  # è‡ªå®šä¹‰é…ç½®
  python run_observable_experiment.py --config my_config.yaml
  
  # æŒ‡å®šæ¨¡å‹å’Œç­–ç•¥
  python run_observable_experiment.py --full --models gpt-3.5-turbo gpt-4 --strategies balanced aggressive
        """
    )
    
    parser.add_argument("--demo", action="store_true", 
                       help="è¿è¡Œå¿«é€Ÿæ¼”ç¤ºå®éªŒ")
    parser.add_argument("--full", action="store_true", 
                       help="è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ")
    parser.add_argument("--config", type=str, 
                       help="ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶")
    
    parser.add_argument("--episodes", type=int, default=100,
                       help="Episodeæ•°é‡ (é»˜è®¤: 100)")
    parser.add_argument("--models", nargs="+", 
                       default=["gpt-3.5-turbo"],
                       help="è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨")
    parser.add_argument("--strategies", nargs="+", 
                       default=["balanced"],
                       help="è¦æµ‹è¯•çš„ç­–ç•¥åˆ—è¡¨")
    
    parser.add_argument("--port", type=int, default=5000,
                       help="Webä»ªè¡¨æ¿ç«¯å£ (é»˜è®¤: 5000)")
    parser.add_argument("--no-web", action="store_true",
                       help="ç¦ç”¨Webä»ªè¡¨æ¿")
    parser.add_argument("--open-browser", action="store_true",
                       help="è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨")
    
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--quiet", "-q", action="store_true",
                       help="é™é»˜æ¨¡å¼")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    if not args.quiet:
        setup_logging(args.verbose)
    
    # æ‰“å°æ¨ªå¹…
    if not args.quiet:
        print_banner()
    
    # æ£€æŸ¥Webä¾èµ–
    if not args.no_web:
        try:
            import flask
            import flask_socketio
        except ImportError:
            print("âš ï¸ WebåŠŸèƒ½éœ€è¦å®‰è£…é¢å¤–ä¾èµ–:")
            print("pip install flask flask-socketio")
            print("æˆ–ä½¿ç”¨ --no-web å‚æ•°ç¦ç”¨WebåŠŸèƒ½")
            return
    
    # å¯åŠ¨æµè§ˆå™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if args.open_browser and not args.no_web:
        import threading
        browser_thread = threading.Thread(
            target=open_dashboard, 
            args=(args.port,),
            daemon=True
        )
        browser_thread.start()
    
    try:
        # æ ¹æ®å‚æ•°è¿è¡Œç›¸åº”çš„å®éªŒ
        if args.demo:
            await run_quick_demo()
        elif args.config:
            await run_custom_experiment(args.config)
        elif args.full:
            await run_full_experiment(args.models, args.strategies, args.episodes)
        else:
            # é»˜è®¤è¿è¡Œæ¼”ç¤º
            print("ğŸ’¡ æœªæŒ‡å®šå®éªŒç±»å‹ï¼Œè¿è¡Œå¿«é€Ÿæ¼”ç¤º")
            print("ä½¿ç”¨ --help æŸ¥çœ‹æ›´å¤šé€‰é¡¹")
            await run_quick_demo()
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
    
    print("\nğŸ‰ æ„Ÿè°¢ä½¿ç”¨å¯è§‚æµ‹å®éªŒç³»ç»Ÿ!")


if __name__ == "__main__":
    asyncio.run(main())