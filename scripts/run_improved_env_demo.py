#!/usr/bin/env python3
"""
è¿è¡Œæ”¹è¿›ç¯å¢ƒçš„å¯è§‚æµ‹æ¼”ç¤º
å±•ç¤ºæ–°çš„ImprovedFlightBookingEnvçš„è¯¦ç»†å¥–åŠ±åˆ†è§£å’ŒæŠ€èƒ½è·Ÿè¸ªåŠŸèƒ½
"""

import asyncio
import logging
import os
import random
import sys
import time
import webbrowser
from typing import Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from experiments.observation_system import ObservationSystem
from test_time_gym.envs.improved_flight_booking_env import (
    ImprovedFlightBookingEnv,
    SkillType,
)


class ImprovedEnvAgent:
    """æ”¹è¿›ç¯å¢ƒçš„æ™ºèƒ½ä½“ï¼ˆå¤šç§ç­–ç•¥ï¼‰"""

    def __init__(self, strategy: str = "balanced"):
        self.strategy = strategy
        self.learned_skills = []
        self.action_history = []
        self.performance_memory = {}

    def select_action(self, observation: Dict) -> str:
        """æ ¹æ®ç­–ç•¥é€‰æ‹©åŠ¨ä½œ"""
        current_view = observation.get('view', 'search_form')
        available_actions = observation.get('available_actions', [])

        if not available_actions:
            return "restart"

        # æ ¹æ®ç­–ç•¥é€‰æ‹©åŠ¨ä½œ
        if self.strategy == "aggressive":
            return self._aggressive_strategy(observation, available_actions)
        elif self.strategy == "conservative":
            return self._conservative_strategy(observation, available_actions)
        elif self.strategy == "learning":
            return self._learning_strategy(observation, available_actions)
        else:  # balanced
            return self._balanced_strategy(observation, available_actions)

    def _aggressive_strategy(self, obs: Dict, actions: List[str]) -> str:
        """æ¿€è¿›ç­–ç•¥ï¼šå¿«é€Ÿå†³ç­–ï¼Œä¼˜å…ˆé€‰æ‹©æœ€ä¾¿å®œçš„é€‰é¡¹"""
        view = obs.get('view')

        if view == 'search_form':
            return "search_flights"
        elif view == 'search_results':
            if 'select_flight cheapest' in actions:
                return "select_flight cheapest"
            elif 'add_to_cart' in actions:
                return "add_to_cart"
            else:
                return actions[0]
        elif view == 'cart':
            return "proceed_to_payment"
        elif view == 'payment':
            if 'confirm_payment' in actions:
                return "confirm_payment"
            elif 'enter_card' in actions:
                return "enter_card"

        return random.choice(actions)

    def _conservative_strategy(self, obs: Dict, actions: List[str]) -> str:
        """ä¿å®ˆç­–ç•¥ï¼šä»”ç»†ç­›é€‰ï¼Œé‡è§†çº¦æŸæ»¡è¶³"""
        view = obs.get('view')

        if view == 'search_form':
            return "search_flights"
        elif view == 'search_results':
            if 'filter_results' in actions:
                return "filter_results"
            elif 'select_flight cheapest' in actions:
                return "select_flight cheapest"
            elif 'add_to_cart' in actions:
                return "add_to_cart"
        elif view == 'cart':
            # æ£€æŸ¥é¢„ç®—
            cart_total = obs.get('cart', {}).get('total', 0)
            budget = obs.get('constraints', {}).get('budget', 1000)
            if cart_total <= budget:
                return "proceed_to_payment"
            else:
                return "restart"  # è¶…é¢„ç®—é‡æ–°å¼€å§‹
        elif view == 'payment':
            if 'confirm_payment' in actions:
                return "confirm_payment"
            elif 'enter_card' in actions:
                return "enter_card"

        return random.choice(actions)

    def _learning_strategy(self, obs: Dict, actions: List[str]) -> str:
        """å­¦ä¹ ç­–ç•¥ï¼šåŸºäºå†å²è¡¨ç°è°ƒæ•´è¡Œä¸º"""
        view = obs.get('view')

        # è®°å½•çŠ¶æ€-åŠ¨ä½œå†å²
        state_key = f"{view}_{len(obs.get('flights', []))}"

        # å¦‚æœæœ‰å†å²è®°å½•ï¼Œé€‰æ‹©è¡¨ç°æœ€å¥½çš„åŠ¨ä½œ
        if state_key in self.performance_memory:
            best_action = max(self.performance_memory[state_key].items(),
                            key=lambda x: x[1])[0]
            if best_action in actions:
                return best_action

        # å¦åˆ™ä½¿ç”¨å¹³è¡¡ç­–ç•¥
        return self._balanced_strategy(obs, actions)

    def _balanced_strategy(self, obs: Dict, actions: List[str]) -> str:
        """å¹³è¡¡ç­–ç•¥ï¼šç»¼åˆè€ƒè™‘æ•ˆç‡å’Œçº¦æŸ"""
        view = obs.get('view')

        if view == 'search_form':
            return "search_flights"
        elif view == 'search_results':
            flights = obs.get('flights', [])
            if flights and len(flights) > 3:
                return "filter_results"
            elif 'select_flight cheapest' in actions:
                return "select_flight cheapest"
            elif 'add_to_cart' in actions:
                return "add_to_cart"
        elif view == 'cart':
            return "proceed_to_payment"
        elif view == 'payment':
            if 'confirm_payment' in actions:
                return "confirm_payment"
            elif 'enter_card' in actions:
                return "enter_card"

        return random.choice(actions)

    def update_performance(self, state_key: str, action: str, reward: float):
        """æ›´æ–°åŠ¨ä½œè¡¨ç°è®°å½•"""
        if state_key not in self.performance_memory:
            self.performance_memory[state_key] = {}

        if action not in self.performance_memory[state_key]:
            self.performance_memory[state_key][action] = []

        self.performance_memory[state_key][action].append(reward)

    def learn_skill(self, skill_name: str, context: Dict):
        """å­¦ä¹ æ–°æŠ€èƒ½"""
        skill_info = {
            'name': skill_name,
            'learned_at': time.time(),
            'context': context,
            'usage_count': 0,
            'success_rate': 0.0
        }
        self.learned_skills.append(skill_info)
        return skill_info


async def run_single_experiment(obs_system: ObservationSystem,
                              experiment_name: str,
                              agent_strategy: str,
                              difficulty: str = "medium",
                              num_episodes: int = 20):
    """è¿è¡Œå•ä¸ªå®éªŒ"""

    print(f"ğŸ® å¼€å§‹å®éªŒ: {experiment_name} (ç­–ç•¥: {agent_strategy}, éš¾åº¦: {difficulty})")

    # åˆ›å»ºç¯å¢ƒå’Œæ™ºèƒ½ä½“
    env = ImprovedFlightBookingEnv(
        seed=42,
        config={
            "difficulty": difficulty,
            "max_steps": 30,
            "progress_weight": 0.1,
            "constraint_weight": 0.3,
            "efficiency_weight": 0.2,
            "optimization_weight": 0.2,
            "completion_weight": 1.0
        }
    )

    agent = ImprovedEnvAgent(strategy=agent_strategy)

    # æŠ€èƒ½å‘ç°è®¡æ•°å™¨
    skills_discovered = 0

    for episode in range(num_episodes):
        episode_id = f"ep_{episode:03d}"

        # é‡ç½®ç¯å¢ƒ
        obs, info = env.reset()

        # è®°å½•episodeå¼€å§‹
        obs_system.log_episode_start(experiment_name, episode_id, obs)

        total_reward = 0.0
        trajectory = []
        step_count = 0

        # æ¨¡æ‹ŸæŠ€èƒ½å­¦ä¹ ï¼ˆåŸºäºç­–ç•¥å’Œepisodeè¿›åº¦ï¼‰
        if agent_strategy == "learning" and episode > 5 and random.random() < 0.2:
            skill_name = f"OptimizedSearch_{skills_discovered+1}"
            skill_info = agent.learn_skill(skill_name, {
                'episode': episode,
                'difficulty': difficulty,
                'strategy': agent_strategy
            })
            skills_discovered += 1

            # è®°å½•æŠ€èƒ½å­¦ä¹ 
            obs_system.log_skill_learned(
                experiment_name,
                skill_name,
                random.uniform(0.6, 0.9),  # æ¨¡æ‹ŸæŠ€èƒ½æˆåŠŸç‡
                usage_count=0
            )

        while not env.done and not env.truncated:
            # æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ
            action = agent.select_action(obs)

            # æ‰§è¡ŒåŠ¨ä½œ
            next_obs, reward, done, truncated, step_info = env.step(action)

            # è®°å½•è½¨è¿¹
            step_data = {
                'step': step_count,
                'action': action,
                'obs': obs,
                'reward': reward,
                'reward_breakdown': step_info.get('reward_breakdown', {}),
                'skill_metrics': step_info.get('skill_metrics', {})
            }
            trajectory.append(step_data)

            # æŠ€èƒ½ä½¿ç”¨æ£€æµ‹
            skill_used = None
            if agent.learned_skills and random.random() < 0.3:
                skill_used = random.choice(agent.learned_skills)['name']
                skill_success = random.random() > 0.3
                obs_system.log_skill_usage(experiment_name, skill_used, skill_success)

            # è®°å½•æ­¥éª¤
            obs_system.log_step(
                experiment_name, episode_id, step_count,
                action, next_obs, reward, skill_used
            )

            total_reward += reward
            step_count += 1
            obs = next_obs

            # æ¨¡æ‹ŸçœŸå®æ‰§è¡Œå»¶è¿Ÿ
            await asyncio.sleep(0.05)

        # åˆ¤æ–­æˆåŠŸ
        success = env.done and not env.truncated
        if step_info and 'constraint_satisfaction' in step_info:
            success = success and step_info['constraint_satisfaction'] > 0.8

        # è®°å½•episodeç»“æŸ
        obs_system.log_episode_end(experiment_name, episode_id, total_reward, success, trajectory)

        # å­¦ä¹ ç­–ç•¥æ›´æ–°æ€§èƒ½è®°å½•
        if agent_strategy == "learning":
            for step_data in trajectory:
                state_key = f"{step_data['obs'].get('view', '')}_{len(step_data['obs'].get('flights', []))}"
                agent.update_performance(state_key, step_data['action'], step_data['reward'])

        # è¿›åº¦æŠ¥å‘Š
        if (episode + 1) % 5 == 0:
            print(f"  ğŸ“Š {experiment_name}: å·²å®Œæˆ {episode + 1}/{num_episodes} episodes")

        # episodeé—´éš”
        await asyncio.sleep(0.2)

    print(f"âœ… {experiment_name} å®Œæˆ! å‘ç°æŠ€èƒ½: {skills_discovered} ä¸ª")


async def run_difficulty_comparison(obs_system: ObservationSystem):
    """è¿è¡Œä¸åŒéš¾åº¦çº§åˆ«çš„å¯¹æ¯”å®éªŒ"""

    print("\nğŸ¯ è¿è¡Œéš¾åº¦çº§åˆ«å¯¹æ¯”å®éªŒ...")

    difficulties = ["easy", "medium", "hard"]
    strategy = "balanced"

    tasks = []
    for difficulty in difficulties:
        experiment_name = f"difficulty_{difficulty}_{strategy}"
        task = asyncio.create_task(
            run_single_experiment(
                obs_system,
                experiment_name,
                strategy,
                difficulty,
                num_episodes=15
            )
        )
        tasks.append(task)

    await asyncio.gather(*tasks)


async def run_strategy_comparison(obs_system: ObservationSystem):
    """è¿è¡Œä¸åŒç­–ç•¥çš„å¯¹æ¯”å®éªŒ"""

    print("\nğŸ§  è¿è¡Œç­–ç•¥å¯¹æ¯”å®éªŒ...")

    strategies = ["aggressive", "conservative", "balanced", "learning"]
    difficulty = "medium"

    tasks = []
    for strategy in strategies:
        experiment_name = f"strategy_{strategy}_{difficulty}"
        task = asyncio.create_task(
            run_single_experiment(
                obs_system,
                experiment_name,
                strategy,
                difficulty,
                num_episodes=20
            )
        )
        tasks.append(task)

    await asyncio.gather(*tasks)


async def run_comprehensive_demo(obs_system: ObservationSystem):
    """è¿è¡Œç»¼åˆæ¼”ç¤º"""

    print("\nğŸš€ è¿è¡Œç»¼åˆæ¼”ç¤ºå®éªŒ...")

    # åŸºç¡€å¯¹æ¯”å®éªŒ
    experiments = [
        ("basic_baseline", "conservative", "medium", 15),
        ("basic_optimized", "learning", "medium", 15),
        ("advanced_strategy", "balanced", "hard", 12)
    ]

    tasks = []
    for exp_name, strategy, difficulty, episodes in experiments:
        task = asyncio.create_task(
            run_single_experiment(
                obs_system,
                exp_name,
                strategy,
                difficulty,
                episodes
            )
        )
        tasks.append(task)

    await asyncio.gather(*tasks)


def print_demo_info():
    """æ‰“å°æ¼”ç¤ºä¿¡æ¯"""
    info = """
ğŸ¯ æ”¹è¿›ç¯å¢ƒæ¼”ç¤ºå†…å®¹:

ğŸ“Š æ ¸å¿ƒç‰¹æ€§éªŒè¯:
  â€¢ è¯¦ç»†å¥–åŠ±åˆ†è§£ç³»ç»Ÿ (base_action, progress, constraint_satisfaction, efficiency, optimization)
  â€¢ æŠ€èƒ½æŒ‡æ ‡è·Ÿè¸ª (search_efficiency, budget_efficiency, constraint_violations)
  â€¢ å¤šéš¾åº¦çº§åˆ«æ”¯æŒ (easy, medium, hard)
  â€¢ ç¡®å®šæ€§ä¸šåŠ¡é€»è¾‘ (å‡å°‘éšæœºæ€§ï¼Œæé«˜å­¦ä¹ æ•ˆæœ)

ğŸ¤– æ™ºèƒ½ä½“ç­–ç•¥å¯¹æ¯”:
  â€¢ aggressive: å¿«é€Ÿå†³ç­–ï¼Œä¼˜å…ˆæœ€ä¾¿å®œé€‰é¡¹
  â€¢ conservative: è°¨æ…å†³ç­–ï¼Œé‡è§†çº¦æŸæ»¡è¶³
  â€¢ balanced: å¹³è¡¡æ•ˆç‡å’Œçº¦æŸ
  â€¢ learning: åŸºäºå†å²è¡¨ç°è‡ªé€‚åº”å­¦ä¹ 

ğŸ” è§‚æµ‹é‡ç‚¹:
  â€¢ å¥–åŠ±åˆ†è§£çš„å®æ—¶å˜åŒ–
  â€¢ ä¸åŒç­–ç•¥çš„æˆåŠŸç‡å·®å¼‚
  â€¢ æŠ€èƒ½å­¦ä¹ å’Œä½¿ç”¨æ¨¡å¼
  â€¢ çº¦æŸæ»¡è¶³åˆ†æ•°æ¼”è¿›
  â€¢ éš¾åº¦çº§åˆ«å¯¹æ€§èƒ½çš„å½±å“

ğŸŒ Webç•Œé¢åŠŸèƒ½:
  â€¢ å®æ—¶å¥–åŠ±åˆ†è§£å¯è§†åŒ–
  â€¢ æŠ€èƒ½å­¦ä¹ æ—¶é—´çº¿
  â€¢ ç­–ç•¥æ€§èƒ½å¯¹æ¯”å›¾è¡¨
  â€¢ çº¦æŸæ»¡è¶³åº¦åˆ†æ

ğŸ’¡ ä½¿ç”¨å»ºè®®:
  1. å¯åŠ¨æ¼”ç¤ºåè®¿é—® http://localhost:5000
  2. è§‚å¯Ÿå®æ—¶æ•°æ®æ›´æ–°
  3. å…³æ³¨å¥–åŠ±åˆ†è§£çš„å˜åŒ–
  4. æ¯”è¾ƒä¸åŒç­–ç•¥çš„è¡¨ç°
  5. æŸ¥çœ‹ç”Ÿæˆçš„è¯¦ç»†æŠ¥å‘Š
"""
    print(info)


async def main():
    """ä¸»å‡½æ•°"""

    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    print("ğŸ”¬ æ”¹è¿›ç¯å¢ƒå¯è§‚æµ‹æ¼”ç¤º")
    print("=" * 60)
    print_demo_info()

    # åˆ›å»ºè§‚æµ‹ç³»ç»Ÿ
    obs_system = ObservationSystem(enable_web=True, web_port=5000)

    # å¯åŠ¨ç›‘æ§
    all_experiments = [
        "basic_baseline", "basic_optimized", "advanced_strategy",
        "difficulty_easy_balanced", "difficulty_medium_balanced", "difficulty_hard_balanced",
        "strategy_aggressive_medium", "strategy_conservative_medium",
        "strategy_balanced_medium", "strategy_learning_medium"
    ]

    obs_system.start_monitoring(all_experiments)

    print("\nğŸŒ Webä»ªè¡¨æ¿å·²å¯åŠ¨: http://localhost:5000")
    print("ğŸ’¡ æ‰“å¼€æµè§ˆå™¨æŸ¥çœ‹å®æ—¶ç›‘æ§ç•Œé¢")

    # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    try:
        webbrowser.open("http://localhost:5000")
        print("ğŸŒ å·²è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨")
    except:
        print("âš ï¸ æ— æ³•è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼Œè¯·æ‰‹åŠ¨è®¿é—® http://localhost:5000")

    print("\nâ³ ç­‰å¾…5ç§’åå¼€å§‹å®éªŒ...")
    await asyncio.sleep(5)

    try:
        # è¿è¡Œæ¼”ç¤ºå®éªŒ
        print("\nğŸš€ å¼€å§‹æ¼”ç¤ºå®éªŒ...")
        await run_comprehensive_demo(obs_system)

        print("\nğŸ¯ è¿è¡Œéš¾åº¦å¯¹æ¯”...")
        await run_difficulty_comparison(obs_system)

        print("\nğŸ§  è¿è¡Œç­–ç•¥å¯¹æ¯”...")
        await run_strategy_comparison(obs_system)

        print("\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
        print("ğŸ“Š è§‚æµ‹æ•°æ®å·²æ”¶é›†å®Œæ¯•")

        # é¢å¤–ç­‰å¾…æ—¶é—´æ¥è§‚å¯Ÿæœ€ç»ˆçŠ¶æ€
        print("\nâ±ï¸ ä¿æŒç³»ç»Ÿè¿è¡Œ60ç§’ä»¥ä¾›è§‚å¯Ÿ...")
        await asyncio.sleep(60)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print("\nğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        obs_system.generate_final_report("logs/improved_env_reports")

        # æ¸…ç†
        obs_system.cleanup()
        print("ğŸ§¹ æ¸…ç†å®Œæˆ")
        print("\nğŸ“ æŠ¥å‘Šæ–‡ä»¶ä½ç½®: logs/improved_env_reports/")
        print("ğŸ“ è¯¦ç»†æ—¥å¿—ä½ç½®: logs/observable_experiment.log")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ”¹è¿›ç¯å¢ƒæ¼”ç¤º!")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–å’Œé…ç½®")
